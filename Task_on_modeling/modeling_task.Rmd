---
title: "Task on Modeling"
author: "Ignacio Almodóvar & Alejandra Estrada"
date: "3/22/2022"
output: pdf_document
---

```{r setup, include=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(magrittr)
library(ggplot2)
library(h2o)
library(tidymodels)
library(infer)
set.seed(123)
```

## Data Explanation

We have chosen a dataset located in kaggle. It contains information about the classification of certain drug types based on different features such as the age, the sex, the blood pressure levels, the cholesterol levels and the sodium-to-potassium ratio.

```{r}
data=read.csv2("drug200.csv",sep = ",",header = TRUE)
data %>% head(5)
```

As it can be seen, most of the variables are categorical with a few levels. Indeed "Age" and "Na_to_K" are the only continuous ones. The last column "Drug" is the response variable, therefore, we will base most of out analysis in this variable.


## Preprocess 

let's search for missing values.

```{r}
missingValues=function(data){ 
  count=0
  a=cbind(lapply(lapply(data, is.na), sum)) 
  for(i in 1:ncol(data)){
    if(a[i]!=0){
      cat("There are", a[i], "missing values in column ", i,"\n" )
      count=count+1
    } 
  }
  if(count==0){
    cat("There are no missing values in this dataset")
  } 
}
missingValues(data)
```


As we can see, the summary says that all variables except Age are factors. However, analyzing the data the variable "Na_to_k" looks like a numeric variable so we must change it.

```{r}
data[,5]  %<>% as.numeric()
summary(data)
```


#Analyze correlation (hacer para variable age y Na_to_K ya que son las únicas continuas)
No se si se podrá distinguir entre tipos de droga para las correlaciones o que. Pero estaría bien ver si se puede sacar alguna conclusion interseante con la correlación.



We now plot the continuous variables to see if we can find any group evidences for the type of drug


```{r}
ggplot(data,aes(Age,Na_to_K,col=Drug)) + geom_point()
```

Beforehand there is not clear evidence for the differentiation in groups given the age and the Na_t_k. However, as can be seen, for the DrugY there is a clear bandwidth for Na_to_k being higher than 15.

We are now going to fitt a classification model using h2o package.

```{r,results=FALSE}
table(data$Drug)
h2o.init()
data_h2o=as.h2o(data)
resp_data="Drug"
pred_data=setdiff(names(data_h2o), resp_data)


setdiff(names(data_h2o), resp_data)
data_h2o[, resp_data] <- as.factor(data_h2o[, resp_data])

splits = h2o.splitFrame(data = data_h2o, ratios = 0.8, seed = 42)
train = splits[[1]]
test = splits[[2]]
# Run AutoML
aml_mul = h2o.automl(x = pred_data, y = resp_data, training_frame = train, leaderboard_frame = test,
                      include_algos = c("GLM", "XGBoost", "DeepLearning","DRF","GBM","StackedEnsemble"),max_runtime_secs = 100,max_runtime_secs_per_model = 100, verbosity = NULL)


```


```{r}
lb_mul <- h2o.get_leaderboard(aml_mul)
print(lb_mul, n = nrow(lb_mul))
```
```{r}
probs <- table(as.matrix(data$Drug))
probs <- probs / sum(probs)
(sum(probs^2))

(mean(1 - probs))
```


```{r}
pred_mul <- h2o.predict(object = aml_mul, newdata = test)
h2o.head(pred_mul)

labels_mul <- as.matrix(pred_mul$predict)
table(labels_mul, as.matrix(test$Drug))

h2o.shutdown(prompt = FALSE)
```
 Como podemos ver ninguno de estos modelos es muy util ya que la clasificación es mala. 


## Tidymodels

We are now going to continue with our analysis but now using some libraries and functions from the package "tidymodels". This is a very versatile package, it includes functions for basically facing every kind of statistical problems.

We can know have a quick-view of our data with the function glimpse(). It is the same data that we have been using in the section before, therefore we already know enough about it.

```{r}
glimpse(data)
data$Drug %<>% as.factor() 
data$Na_to_K %<>% as.numeric() 
```

Probably one of the most useful packages that tidy includes is "rsample" within it we can draw different samples from the main data and work with them to do different analysis. To test an work with this library we are going to use bootstraps() to obtain observations of the dataset with replacement. With these datasets we are going to fit different multinomial models for multiclass classification also using a tidy package parnsip, which helps to build several models.

Therefore we first create the bootstrap object and ask for 5 different samples. We can access to each sample with analysis() function. Also, with the assesment() function we can access to what will be our "test data".

```{r}
boot_data <- bootstraps(data, times = 5,apparent = TRUE)
analysis(boot_data$splits[[1]]) %>% head(4)
```

We now want to build a model that allows to do classification over our dataset. To do that we are going to use a multinomial regression model with a neural network engine. 

```{r}
?details_multinom_reg_nnet
mult_reg=multinom_reg() %>% set_engine("nnet") %>% set_mode("classification")
```

Once we have the model set up we can fit it with the different samples.

```{r}
boot_fit=list()
for (i in 1:5) {
  boot_fit[[i]] <- mult_reg %>%
    fit(Drug ~ ., data = analysis(boot_data$splits[[i]]))
}
```

Then we can evaluate them with the test data also given by the bootstrap function. We are going to do different predictions for each model and then compare it with its test to see how well the classification was done.

```{r}
prediction=list()
prediction_percentage=c()
for (i in 1:5) {
  prediction[i]=predict(boot_fit[[i]],assessment(boot_data$splits[[i]]))
}

for (i in 1:5) {
  prediction_percentage[i]=mean(prediction[[i]] == assessment(boot_data$splits[[i]])$Drug)
}

prediction_percentage
```

As we can see from the percentages for predictions that were right, most of the models are actually very good. In fact, all of them are over 0.98%, which means that it is almost predicting perfectly. 

However, this bootstrap example was done just for educational purposes. It is usually better to use most of the data without replacement available to fit a model. Also, as we saw that using this approach we could get over an 98% of the prediction correctly, we would now try another method but now using all the data available.

We are now going to split again the dataset. But this time into training and testing, again using the rsample package.

```{r}
drugs_split=initial_split(data,strata = Na_to_K,prop = 0.7)
drugs_train <- training(drugs_split)
drugs_test <- testing(drugs_split)
```

And now we create another model. We are going to go now with a boost_tree model, using the engine "xgboost" for multiclass classification. Again, we create and fit the model:


```{r,warning=FALSE,results=FALSE}
tree_spec=boost_tree() %>% set_engine("xgboost") %>% set_mode("classification")

tree_fit <- tree_spec %>%
  fit(Drug ~ ., data = drugs_train)
```

Once we have the model fitted we can check its accuracy for predictions. To do that we use predict and obtain its confusion matrix.

```{r}
test_results <- bind_cols(
  dplyr::select(drugs_test, "Drug"),
  predict(tree_fit, drugs_test))

table(test_results$Drug, test_results$.pred_class)
```

From the output we can see that the prediction has an accuracy of almost 100%, which means that our model is working very good. Indeed it is able to predict perfectly the type of Drug that a person should be taking given the predictors seen in this analysis.

Once we have a good predictive model we are going to do a little bit of inference on our dataset. To do this we are going to use the "infer" package, which is also part of tidymodels. We are going to analyze if the mean age of the sample is anywhere close to the real population, where we know that the mean age in 2015 was 42.5 in Spain which will be our null hypothesis.

```{r}
age_estimator = data %>% specify(response=Age) %>% calculate(stat = "mean")
null_dist <- data %>% specify(response=Age) %>%
   hypothesize(null = "point",mu=42.5) %>%
   generate(reps = 1000, type = "bootstrap") %>%
   calculate(stat = "mean")

visualize(null_dist) +
  shade_p_value(obs_stat = age_estimator, direction = "two_sided")
```

From the plot we can see that the mean population of the sample lies on a tail of the null hypothesis. Therefore, observing the sample mean of 44.315 looks a little bit unlikely. However, we still have to check how unlikely this is. To obtain so we calculate the p-value.

```{r}
p_value <- null_dist %>%
  get_p_value(obs_stat = age_estimator, direction = "two_sided")
p_value
```

We can see that the p_value obtained is small, but not very much. Which means, that the probability of the sample mean being this far from 42.5 is 0.13. Nevertheless, we still have to calculate the confidence interval for these results. We will calculate it for a confidence level of $\alpha=0.05$.

```{r}
null_dist %>% get_confidence_interval(point_estimate = age_estimator, level = .95, type = "se")
```

As it can be seen, 42.5 lies inside this interval, which means that the p-value is not statistically significant at an $\alpha=0.05$ confidence level.


